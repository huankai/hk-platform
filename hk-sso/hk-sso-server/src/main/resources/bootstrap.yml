server:
  port: 8086
spring:
  application:
    name: hk-sso-server
  main:
    banner-mode: 'off'
    allow-bean-definition-overriding: true
  cloud:
########################################################################### spring cloud config 配置
    config:
    # 使用服务现在加载配置，需要将服务发现(eureka)配置在 bootstrap上下文中，不然会报错
#      discovery:
#        enabled: true
#        # 注册中心服务名称
#        service-id: hk-config-server
    # 使用 版本管理(git) 加载配置
    # 默认为 master分支，因为配置中心使用的是本地配置，所以注释了 label属性
#      label: "2.1.0.RELEASE"
    # 要激活的属性，默认为 default, 文件名为 ${spring.application.name}-${spring.cloud.config.profile}.yml
      profile: dev
      uri: http://127.0.0.1:8770
########################################################################### spring cloud stream 配置
    stream:
      # 当有多个binder时(如kafka、rabbitmq)，默认的binder
      default-binder: kafka
      # 应用已部署实例的数量。如果使用Kafka和分区，必须要设置。
      instance-count: 3
      kafka:
        binder:
          # Kafka绑定（binder）将连接到的代理（broker）列表
          brokers:
            - sjq-01:9092
            - sjq-02:9092
            - sjq-03:9092

          # 自动创建 topic，默认值为 true，如果topic不存在，会自动创建，如果设置为false,binder无法启动
          auto-create-topics: true

          # 如果设置为true，则绑定（binder）将根据需要创建添加新分区。
          # 如果设置为false，则绑定（binder）将依赖于已经配置的主题的分区大小。
          # 如果目标主题的分区数量小于期望值，绑定（binder）将无法启动
          auto-add-partitions: false

          # 仅在 auto-create-topics 或 auto-add-partitions 为true时有效，
          # 绑定（binder）将在其生产/消费数据的主题（topic）上配置的分区的全局最小数量。
          # 它可以被生产者的partitionCount设置或生产者的instanceCount * concurrency设置的值所替代（其中较大的值）。
          min-partition-count: 2

          #以秒为单位等待分区信息的时间，默认为 60，如果此计时器到期，运行状态将报告down.
          health-timeout: 30

          # 创建 topic 副本数，默认为 1
          replication-factor: 2
        bindings:
          input:
            #通道内容类型，默认为 application/json
            #content-type: "application/json"

            # 消费者组
            #group: ""

            #
            #destination: ""

            # 设置binder类型，当classpath下有多个 Binder依赖时，必须指定 使用哪个binder来绑定所有的通道,查看　META-INF/spring.binders　文件中 key
            # 提供的其它binder（如 rabbitmq）也会有这样的文件,自定义binder实现也需要提供这样的文件
            # 可以使用 default-binder为每个通道配置binder
            #binder: "kafka"
            consumer:
              # 流入消费者的并发性
              concurrency: 1

              # 消费者是否接受来自一个分区的生产者数据
              partitioned: false

              # 当设置为大于等于0的值的时候，允许自定义此消费者的实例数量
              instance-count: -1

              # 当设置为大于等于0的值的时候，允许自定义此消费者的实例索引
              instance-index: -1

              # 如果处理失败，则尝试处理该消息的次数（包括第一次）。 设置为1以禁用重试，默认为 3
              max-attempts: 3

              #
              back-off-initial-interval: 1000

              #
              back-offmax-interval: 10000

              # 回退乘数
              back-off-multiplier: 2.0

              #
              # header-mode: "none"

              #
              use-native-decoding: false

          # 配置 output 生产者
          output:
            #默认为 application/json
            #content-type: "application/json"
            group: abc
              # 设置binder类型，当classpath下有多个 Binder依赖时，必须指定 使用哪个binder来绑定所有的通道,查看　META-INF/spring.binders　文件中 key
              # 提供的其它binder（如 rabbitmq）也会有这样的文件,自定义binder实现也需要提供这样的文件
              # 可以使用 default-binder为每个通道配置binder
              #binder: "kafka"

              #producer:

                # partition-key-extractor-name: ""

                #partition-selector-name: ""

                # 数据的目标分区的数量（如果分区已启用）。 如果生产者是分区的，则必须设置为大于1的值。 在Kafka上意味着使用 此值和目标主题分区数量中的较大值。
                # partition-count: 2

                # 设置为true时，流出消息将直接由客户端库序列化，客户端库必须相应地进行配置（例如，设置适当的Kafka生产者value serializer）。
                # 使用此配置时，流出消息编组不是基于绑定的contentType。 当使用本地编码时，消费者有责任使用适当的解码器（例如：Kafka消费者value de-serializer）来反序列化流入消息。
                # 而且，当使用本地编码/解码时，headerMode = embeddedHeaders属性将被忽略，并且头部不会嵌入到消息中。
                #use-native-encoding: false

                # 设置为true时，如果binder支持异步发送结果; 发送失败的消息将被发送到目的地（destination）的错误通道
                #error-channel-enabled : false
#    bus:
##      trace:
#        enabled: true
#    stream:
#      kafka:
#        binder:
#          brokers: 192.168.64.128:9092,192.168.64.129:9092,192.168.64.130:9092

########################################################################### spring boot admin 配置
#  boot:
#    admin:
#      client:
#        url: "http://127.0.0.1:9999"
#        instance:
#          prefer-ip: false
#          service-url: "http://127.0.0.1:${server.port}"

########################################################################### management 配置
management:
  endpoints:
    web:
      exposure:
        #启动所有监控端口
        include: "*"
  endpoint:
    health:
     #查看详细的应用健康信息，如数据库的连接、redis的连接等，默认为 never
      show-details: always
#    bus-env:
#      enabled: true


